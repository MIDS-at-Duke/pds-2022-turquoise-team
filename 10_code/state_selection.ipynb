{
 "cells": [
  {
   "cell_type": "code",

   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [

    "## <center> Reading in Data </center>\n",
    "<center> We've collected our data from the below sources: </center>\n",
    "<br>\n",
    "\n",
    "<center> <a href=\"https://www.census.gov/data/datasets/time-series/demo/popest/2010s-state-total.html\" target=\"_blank\"> State Population Data</a> </center>\n",
    "<br>\n",
    "<center> <a href=\"http://www.usa.com/rank/us--average-education-index--state-rank.htm\" target=\"_blank\">State Educational Ranking Data</a> </center>\n",
    "<br>\n",
    "\n",
    "<center> <a href=\"https://ssti.org/blog/useful-stats-capita-personal-income-state-2010-2015\" target=\"_blank\">State Income Data</a> </center>\n",
    "<br>\n",
    "<center> <a href=\"https://wonder.cdc.gov/ucd-icd10.html\" target=\"_blank\">Crude Death Rate where Drug Overdose is the Cause of Death Data</a> </center>\n",
    "\n",
    "\n",
    "\n"

   ]
  },
  {
   "cell_type": "code",

   "execution_count": 2,

   "metadata": {},
   "outputs": [],
   "source": [
    "state_income_data_url = 'https://raw.githubusercontent.com/wafiakmal/Turquoise-Team-Data-Analysis-DS-Salaries/main/00_Raw_Data/pds/state%20income%202010.csv'\n",
    "state_income = pd.read_csv(state_income_data_url)\n",
    "\n",
    "state_educ_url = 'https://raw.githubusercontent.com/wafiakmal/Turquoise-Team-Data-Analysis-DS-Salaries/main/00_Raw_Data/pds/states%20education%20rank%202010%20thru%202014.csv'\n",
    "state_educ = pd.read_csv(state_educ_url)\n",
    "\n",
    "policy_url = 'https://raw.githubusercontent.com/wafiakmal/Turquoise-Team-Data-Analysis-DS-Salaries/main/00_Raw_Data/pds/States%20with%20missing%20policys.csv'\n",
    "missing_policy = pd.read_csv(policy_url)\n",
    "\n",
    "state_pop_url = 'https://raw.githubusercontent.com/wafiakmal/Turquoise-Team-Data-Analysis-DS-Salaries/main/00_Raw_Data/pds/state%20population%202010.csv'\n",
    "state_pop = pd.read_csv(state_pop_url)\n",
    "\n",
    "state_crud_death_url = 'https://raw.githubusercontent.com/wafiakmal/Turquoise-Team-Data-Analysis-DS-Salaries/main/00_Raw_Data/pds/Underlying%20Cause%20of%20Death%2C%201999-2020.csv'\n",

    "state_crud_death = pd.read_csv(state_crud_death_url)\n",
    "\n",
    "\n",
    "\n"

   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging data where the matching key is State"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 18,

   "metadata": {},
   "outputs": [],
   "source": [
    "to_merge_data_frames = [state_income, state_educ, missing_policy, state_pop, state_crud_death]\n",
    "df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['State'],\n",
    "                                            how='outer'), to_merge_data_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping NA to get rid of NA row and District of Columbia"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 19,

   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_merged.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating columns to calculate averages\n",
    "Per state (Florida, Texas, Washington), we're comparing their educational ranking, population from 2010, crude death rate (where cause of death is related to a drug overdose), and income. Below is an example.  \n",
    "<center> income(state_x)/income(Florida) </center>\n",
    "<br>\n",
    "We're comparing these demographics to our three states to ensure that the chosen states are similar and proper for comparison.\n",
    "<br>\n",
    "<br>\n",
    "We're also creating a flag column to evaluate each state's policy on the opioid crisis, which is based on Table 1 from: \n",
    "<br>\n",
    "<br>\n",
    "<center> <em> How States Are Tackling the Opioid Crisis: </em> </center>\n",
    "<center> <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5349480/\" target=\"_blank\">Read paper here</a> </center>\n",
    "<br>\n",
    "<p> This paper is from 2017, however we're comfortable using this data as we're counting which policies are missing in each state. Therefore, if the policy is missing in 2017, then we can reasonably assume that the policy was missing in 2010 as well.\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 20,

   "metadata": {},
   "outputs": [],
   "source": [
    "for states in df_merged['State']:\n",
    "    income_percent = df_merged['2010 average income']/38718.0\n",
    "    df_merged['df_merged_income_fl'] = income_percent\n",
    "    income_percent1 = df_merged['2010 average income']/42821.0\n",
    "    df_merged['df_merged_income_wash'] = income_percent1\n",
    "    income_percent2 = df_merged['2010 average income']/38282.0\n",
    "    df_merged['df_merged_income_tx'] = income_percent2\n",
    "\n",
    "    edu_percent = df_merged['Education Rank']/37.0\n",
    "    df_merged['df_merged_edu_fl'] = edu_percent\n",
    "    edu_percent1 = df_merged['Education Rank']/9.0\n",
    "    df_merged['df_merged_edu_wash'] = edu_percent1\n",
    "    edu_percent2 = df_merged['Education Rank']/43.0\n",
    "    df_merged['df_merged_edu_tx'] = edu_percent2\n",
    "\n",
    "    pop_percent = df_merged['2010 popula tion ']/18801310.0\n",
    "    df_merged['df_merged_pop_fl'] = pop_percent\n",
    "    pop_percent1 = df_merged['2010 popula tion ']/6724540.0\n",
    "    df_merged['df_merged_pop_wash'] = pop_percent1\n",
    "    pop_percent2 = df_merged['2010 popula tion ']/25145561.0\n",
    "    df_merged['df_merged_pop_tx'] = pop_percent2\n",
    "\n",
    "    crude_percent = df_merged['Crude Rate']/16.2701\n",
    "    df_merged['df_merged_crude_fl'] = crude_percent\n",
    "    crude_percent1 = df_merged['Crude Rate']/13.6069\n",
    "    df_merged['df_merged_crude_wash'] = crude_percent1\n",
    "    crude_percent2 = df_merged['Crude Rate']/9.5206\n",
    "    df_merged['df_merged_crude_tx'] = crude_percent2\n",
    "\n",
    "    policy_flag = df_merged['Sum of MISSING from Questionarre ']\n",
    "    df_merged['df_merged_policy_flag_fl'] = policy_flag > 4.0\n",
    "    policy_flag1 = df_merged['Sum of MISSING from Questionarre ']\n",
    "    df_merged['df_merged_policy_flag_wash'] = policy_flag1 > 3.0\n",
    "    policy_flag2 = df_merged['Sum of MISSING from Questionarre ']\n",
    "    df_merged['df_merged_policy_flag_tx'] = policy_flag1 > 5.0\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_metrics = df_merged.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After calculating comparisons\n",
    "After we create the columns that compare demographics to Flordia, Texas, and Washington, respectively, we compute an average of each comparison. We're using this as a measure of \"closeness.\""
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 21,

   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics['eval_metric_fl'] = df_metrics[[\"df_merged_income_fl\", \"df_merged_edu_fl\", \"df_merged_pop_fl\", \"df_merged_crude_fl\"]].mean(axis=1)\n",
    "df_metrics['eval_metric_tx'] = df_metrics[[\"df_merged_income_tx\", \"df_merged_edu_tx\", \"df_merged_pop_tx\", \"df_merged_crude_tx\"]].mean(axis=1)\n",
    "df_metrics['eval_metric_wash'] = df_metrics[[\"df_merged_income_wash\", \"df_merged_edu_wash\", \"df_merged_pop_wash\", \"df_merged_crude_wash\"]].mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating bounds for \"closeness\" \n",
    "After averaging the comparisons, we are filtering such that states that are 20% +/- 100% of our initial states (Texas, Washington, Florida). "
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 22,

   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_new_col(row):\n",
    "    if row['eval_metric_fl'] <= 1.2 and row['eval_metric_fl'] >= 0.8:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "df_metrics['in_bounds_fl'] = df_metrics.apply(lambda row: calc_new_col(row), axis=1)\n",
    "\n",
    "\n",
    "def calc_new_col_wash(row):\n",
    "    if row['eval_metric_wash'] <= 1.2 and row['eval_metric_wash'] >= 0.8:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "df_metrics['in_bounds_wash'] = df_metrics.apply(lambda row: calc_new_col_wash(row), axis=1)\n",
    "\n",
    "\n",
    "def calc_new_col_tx(row):\n",
    "    if row['eval_metric_tx'] <= 1.2 and row['eval_metric_tx'] >= 0.8:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "df_metrics['in_bounds_tx'] = df_metrics.apply(lambda row: calc_new_col_tx(row), axis=1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using our bounds and chosing states based on their implemented policies\n",
    "After bounding our comparison metric, we're selecting states where the bound is satisfied and the quantity of missing policies is greated than our comparison states (Texas, Florida, Washington)."
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 23,

   "metadata": {},
   "outputs": [],
   "source": [
    "df_florida = df_metrics[((df_metrics['in_bounds_fl']==True) & (df_metrics['df_merged_policy_flag_fl'] == True))]\n",
    "df_washington = df_metrics[((df_metrics['in_bounds_wash']==True) & (df_metrics['df_merged_policy_flag_wash'] == True))]\n",
    "df_texas = df_metrics[((df_metrics['in_bounds_tx']==True) & (df_metrics['df_merged_policy_flag_tx'] == True))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below are dataframes containing the states that will be used in our analysis for comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We're analyzing Flordia against: California, Nevada, New York, and Texas"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate = {\"States\":[]}\n",
    "for i in df_florida['State']:\n",
    "    intermediate['States'].append(i)\n",
    "\n",
    "FL_control = pd.DataFrame(intermediate)\n",
    "\n",
    "filepath = Path('../20_intermediate_files/fl_control.csv')\n",
    "FL_control.to_csv(filepath)"


   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We're analyzing Washington against: Alaska, Hawaii, Iowa, Kansas, Maine, Massachusetts, Minnesota, Montana, Nebraska, North Dakota, Oregon, South Dakota, Virginia, and Wyoming"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate = {\"States\":[]}\n",
    "for i in df_washington['State']:\n",
    "    intermediate['States'].append(i)\n",
    "\n",
    "WA_control = pd.DataFrame(intermediate)\n",
    "\n",
    "filepath = Path('../20_intermediate_files/wa_control.csv')\n",
    "WA_control.to_csv(filepath)"

   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We're analyzing Texas against: Arkansas, California, Georgia, Missouri, New York, and Wyoming"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate = {\"States\":[]}\n",
    "for i in df_texas['State']:\n",
    "    intermediate['States'].append(i)\n",
    "\n",
    "TX_control = pd.DataFrame(intermediate)\n",
    "\n",
    "filepath = Path('../20_intermediate_files/tx_control.csv')\n",
    "TX_control.to_csv(filepath)"

   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],

   "source": [
    "intermediate = {\"States\":[]}\n",
    "for i in df_florida['State']:\n",
    "    intermediate['States'].append(i)\n",
    "for i in df_washington['State']:\n",
    "    intermediate['States'].append(i)\n",
    "for i in df_texas['State']:\n",
    "    intermediate['States'].append(i)\n",
    "\n",
    "states_control = pd.DataFrame(intermediate)\n",
    "\n",
    "filepath = Path('../20_intermediate_files/states_control.csv')\n",
    "states_control.to_csv(filepath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {

    "hash": "8809fa16c7855c80da7c7f5e4db812dad5d47ab731d42a7895804fcd7eb8521f"

   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
